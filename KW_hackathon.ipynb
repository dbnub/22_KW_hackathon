{"cells":[{"cell_type":"markdown","source":["## 광운대학교 AI 해커톤  \n","\n","안녕하세요 저희는 이번 광운대학교 AI 해커톤에 참가한 'n을뒤집으면u' 팀입니다.  \n","이번 기회에 처음으로 Image data를 다루게 되어 우여곡절을 겪으며 많은 것을 배울 수 있었습니다.  \n","이번 대회 다들 정말 고생 많으셨고, 아직 많이 부족하지만 저희 팀 코드를 공유합니다!  \n","\n","---------------------------------------------------------------------------  \n","저희 팀은 Colab Pro 버전을 사용하였습니다.  \n","전체적인 코드는 baseline과 크게 다르지 않습니다.  \n","\n","## 참고 자료  \n","이전에 유사한 데이터로 진행된 대회 코드들을 참고 했습니다.  \n","[EfficientNet-b8, TTA 참고 자료](https://dacon.io/competitions/official/235697/codeshare/2429?page=1&dtype=recent)  \n","[CheckPoint 참고 자료](https://dacon.io/competitions/official/235697/codeshare/2441?page=1&dtype=recent)  \n","[Loss Function 참고 자료](https://dacon.io/competitions/official/235697/codeshare/2354?page=1&dtype=recent)  \n","[Swish activation function 참고 자료_1](https://dacon.io/competitions/official/235697/codeshare/2445?page=1&dtype=recent)  \n","[Swish activation function 참고 자료_2](https://blog.ceshine.net/post/pytorch-memory-swish/)  \n","[Augmentation 참고 자료](https://www.dacon.io/competitions/official/235697/codeshare/2437?page=2&dtype=recent)  \n","\n","## 사용 모델  \n","- Resnet50_v2  \n","- EfficientNet-b8  \n","\n","서로 다른 activation function을 사용하는 모델을 앙상블하기 위해 Resnet과 EfficientNet을 사용했습니다.  \n","EfficientNet은 무겁지만 좋은 성능을 위해 b8 모델을 사용했고, Resnet은 비교적 학습 속도가 빠르고 성능도 괜찮다고 알려진 Resnet50_v2 모델을 사용했습니다.  \n","\n","## 학습 방법  \n","- Resnet50_v2 (3 folds, epoch 40, batch size 32)  \n","- EfficientNet-b8 (5 folds, epoch 30, batch size 16 / 12)  \n","- Augmentation은 처음에 Flip과 Rotation을 사용했으나 Rotation만 사용했을 때 점수가 약간 더 높았습니다.  \n","- 9월 29일 이후로 본격적인 학습을 시작하게 되어 시간적 / 물리적 한계로 비교적 적은 fold와 epoch로 학습했고, EfficientNet-b8의 경우, Colab gpu 할당량을 초과하는 학습 시간이 필요해서 Check Point를 설정 했습니다.  \n","- EfficientNet-b8의 초기 학습은 batch size 16으로 진행했고, Check Point를 불러와서 학습할 때는 메모리 상의 문제로 batch size를 12로 수정하여 학습 시켰습니다.\n","- optimizer, scheduler는 baseline과 동일하고, scheduler의 경우엔 gamma를 0.9로 설정 했습니다.\n","- loss function은 MultiLabelSoftMarginLoss를 사용 했습니다.\n","- valid accuracy가 일정 횟수(코드에서는 4회)동안 증가하지 않으면 early stopping 시켰습니다.\n","- 후처리로 TTA(90~360도 회전)와 soft voting(threshold 0.4)을 했습니다.  \n","\n","## 특이 사항  \n","최종 제출 코드를 재현하기 위해 알아두셔야 할 사항들 입니다.\n","- Check Point를 이용하는 경우, checkpoint 폴더를 추가 생성하셔야 문제없이 작동합니다.  \n","- Resnet50_v2 모델은 3 folds 중 fold 1, fold 2만 사용 되었습니다. (fold 0 제외)  \n","- EfficientNet-b8 모델은 5 folds 중 fold 0~3까지만 사용 되었습니다. (fold 4 제외)  \n"," \n","최종 제출일에 학습 도중 런타임 만료가 되는 이슈가 있어서 예정과 다르게 미완성된 모델을 사용하게 되었습니다.  "],"metadata":{"id":"Mt6sIcu6Y0Pe"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19338,"status":"ok","timestamp":1665058794760,"user":{"displayName":"유건혁","userId":"07388571815745735810"},"user_tz":-540},"id":"S76sGVkhxrtE","outputId":"53b3fa35-35d0-4bcb-e489-4ad9b962a2c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"bsBqc7w7_HA8"},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0lFSzTFd0qGc"},"outputs":[],"source":["from google.colab import output\n","# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\n","!cp \"/content/drive/MyDrive/광운대 해커톤/data.zip\" \"data_2.zip\"\n","\n","# data_2.zip을 현재 디렉터리에 압축해제\n","!unzip \"data_2.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gWh_EqOX6fy-"},"outputs":[],"source":["from google.colab import output\n","# 현재 디렉터리에 dirty_mnist라는 폴더 생성\n","!mkdir \"./dirty_mnist\"\n","#dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\n","!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist/\"\n","# 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\n","!mkdir \"./test_dirty_mnist\"\n","#test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\n","!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist/\"\n","# 출력 결과 지우기\n","output.clear()"]},{"cell_type":"markdown","metadata":{"id":"eHtkYutm_Jfo"},"source":["## Library Import"]},{"cell_type":"code","source":["!pip3 install efficientnet_pytorch ttach"],"metadata":{"id":"rZ4INQBV-gH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RPgJyf8_QSu"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from tqdm import tqdm\n","import imutils\n","import zipfile\n","import os\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","import torchvision.transforms as T\n","from torch.utils.data import DataLoader, Dataset\n","from google.colab import output\n","import albumentations\n","import ttach as tta\n","\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정"]},{"cell_type":"markdown","source":["## Random Seed Setting"],"metadata":{"id":"21MOnAniH8yh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyrJi4s1SIdT"},"outputs":[],"source":["import random\n","\n","def seed_everything(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","seed_everything(42)"]},{"cell_type":"markdown","metadata":{"id":"TR4Lr-ml_S1V"},"source":["## Dataset Compose"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yq_wAhpKBR9E"},"outputs":[],"source":["dirty_mnist_answer = pd.read_csv(\"dirty_mnist_2nd_answer.csv\")\n","# dirty_mnist라는 디렉터리 속에 들어있는 파일들의 이름을 \n","# namelist라는 변수에 저장\n","namelist = os.listdir('./dirty_mnist/')\n","\n","# numpy를 tensor로 변환하는 ToTensor 정의\n","class ToTensor(object):\n","    \"\"\"numpy array를 tensor(torch)로 변환합니다.\"\"\"\n","    def __call__(self, sample):\n","        image, label = sample['image'], sample['label']\n","        # swap color axis because\n","        # numpy image: H x W x C\n","        # torch image: C X H X W\n","        image = image.transpose((2, 0, 1))\n","        return {'image': torch.FloatTensor(image),\n","                'label': torch.FloatTensor(label)}\n","# to_tensor 선언\n","to_tensor = T.Compose([\n","                        ToTensor()\n","                    ])\n","    \n","\n","\n","\n","class DatasetMNIST(torch.utils.data.Dataset):\n","    def __init__(self,\n","                 dir_path,\n","                 meta_df,\n","                 transforms=to_tensor,#미리 선언한 to_tensor를 transforms로 받음\n","                 augmentations=None):\n","        \n","        self.dir_path = dir_path # 데이터의 이미지가 저장된 디렉터리 경로\n","        self.meta_df = meta_df # 데이터의 인덱스와 정답지가 들어있는 DataFrame\n","\n","        self.transforms = transforms# Transform\n","        self.augmentations = augmentations # Augmentation\n","        \n","        \n","    def __len__(self):\n","        return len(self.meta_df)\n","    \n","    def __getitem__(self, index):\n","        # 폴더 경로 + 이미지 이름 + .png => 파일의 경로\n","        # 참고) \"12\".zfill(5) => 000012\n","        #       \"146\".zfill(5) => 000145\n","        # cv2.IMREAD_GRAYSCALE : png파일을 채널이 1개인 GRAYSCALE로 읽음\n","        image = cv2.imread(self.dir_path +\\\n","                           str(self.meta_df.iloc[index,0]).zfill(5) + '.png',\n","                           cv2.IMREAD_GRAYSCALE)\n","        \n","        # 0 ~ 255의 값을 갖고 크기가 (256,256)인 numpy array를\n","        # 0 ~ 1 사이의 실수를 갖고 크기가 (256,256,1)인 numpy array로 변환\n","        image = (image/255).astype('float')[..., np.newaxis]\n","        \n","\n","        # 정답 numpy array생성(존재하면 1 없으면 0)\n","        label = self.meta_df.iloc[index, 1:].values.astype('float')\n","        sample = {'image': image, 'label': label}\n","\n","        # transform 적용\n","        # numpy to tensor\n","        if self.transforms:\n","            sample = self.transforms(sample)\n","        # augmentation\n","        if self.augmentations:\n","          \n","          sample['image']= self.augmentations(sample['image'])\n","        \n","\n","        # sample 반환\n","        return sample"]},{"cell_type":"markdown","metadata":{"id":"rfc-d5fF_ooY"},"source":["## Model  \n","Resnet50 모델의 weight는 imagenet1k_v2를 사용했으며, overfit 방지를 위해 dropout layer를 추가했습니다.  \n","학습 과정에서 loss function으로 MultiLabelSoftMarginLoss을 사용하기 때문에 fc layer에 sigmoid를 적용하지 않았습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNVbKo7bylwg"},"outputs":[],"source":["\n","from efficientnet_pytorch import EfficientNet\n","import torch.nn.functional as F\n","from torchvision.models import resnet50, ResNet50_Weights\n","\n","# nn.Module을 상속 받아 Resnet50_v2를 정의\n","class Resnet50(nn.Module):\n","    def __init__(self):\n","        super(Resnet50, self).__init__()\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\n","        self.resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.FC = nn.Linear(1000, 26)\n","\n","\n","    def forward(self, x):\n","        \n","        # resnet을 추가\n","        x = self.conv2d(x)\n","        x = F.relu(self.resnet(x))\n","        x = self.dropout(x)\n","        x = self.FC(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVU591Umr3ct"},"outputs":[],"source":["class Swish(nn.Module):\n","    def forward(self, x):\n","        return x * torch.sigmoid(x)\n","\n","# A memory-efficient implementation of Swish function\n","class SwishImplementation(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, i):\n","        result = i * torch.sigmoid(i)\n","        ctx.save_for_backward(i)\n","        return result\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        i = ctx.saved_tensors[0]\n","        sigmoid_i = torch.sigmoid(i)\n","        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n","\n","class MemoryEfficientSwish(nn.Module):\n","    def forward(self, x):\n","        return SwishImplementation.apply(x)\n","\n","class Efficientnet(nn.Module):\n","    def __init__(self):\n","        super(Efficientnet, self).__init__()\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.swish = MemoryEfficientSwish()\n","        self.FC = nn.Linear(1000, 26)\n","        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b8',advprop=True)\n","\n","\n","    def forward(self, x):\n","        x = self.conv2d(x)\n","        # efficientnet을 추가\n","        x = self.efficientnet(x)\n","        x = self.dropout(x)\n","        x = self.swish(x)\n","        x = self.FC(x)\n","        return x"]},{"cell_type":"markdown","source":["## Check Point"],"metadata":{"id":"TWBhonHcFaOX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NcRWnUqo1mGW"},"outputs":[],"source":["#체크포인트 파일 생성\n","\n","PATH_CP = \"/content/drive/MyDrive/광운대 해커톤/checkpoint/checkp.pt\"\n","\n","if not os.path.exists(PATH_CP):\n","    with open(PATH_CP, 'w'): \n","        pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QrOBkbi0mf_t"},"outputs":[],"source":["#checkpoint file이 비어있는지 확인\n","os.path.getsize(PATH_CP) ==0"]},{"cell_type":"markdown","metadata":{"id":"8At8CaBw_s-O"},"source":["## Train  \n","저희 팀은 장시간 코드를 돌리다가 여러 우여곡절을 겪었습니다.  \n","대부분 이미 알고 계실테지만 혹시라도 필요하신 분들을 위해 [colab run time 유지 방법](https://www.dacon.io/forum/405904)을 첨부합니다.  \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PVsATH1FlTRN"},"outputs":[],"source":["\n","# cross validation을 적용하기 위해 KFold 생성\n","from sklearn.model_selection import KFold\n","kf = KFold(n_splits=3, shuffle=True, random_state=42)\n","\n","# dirty_mnist_answer에서 train_idx와 val_idx를 생성\n","folds=[]\n","for fold_index, (trn_idx, val_idx) in enumerate(kf.split(dirty_mnist_answer),1):\n","    folds.append((trn_idx, val_idx))\n","\n","checkpoint =0\n","epoch_cp = 0\n","valid_loss = 0\n","fold_cp = 0\n","num_epoch = 40\n","for fold in range(3):\n","    print(f'[folds: {fold}]')\n","    # cuda cache 초기화\n","    torch.cuda.empty_cache()\n","\n","    #fold별로 train_idx와 val_idx 설정 \n","    trn_idx = folds[fold][0]\n","    val_idx = folds[fold][1]\n","\n","    #train fold, validation fold 분할\n","    train_answer = dirty_mnist_answer.iloc[trn_idx]\n","    test_answer  = dirty_mnist_answer.iloc[val_idx]\n","\n","    #적용할 augmentation 설정\n","    train_transform = T.Compose([\n","            T.ToPILImage(),\n","            T.RandomRotation(180),\n","            T.ToTensor()\n","        ])\n","    \n","    valid_transform = T.Compose([\n","            T.ToPILImage(),\n","            T.ToTensor()\n","        ])\n","    \n","    #Dataset 정의\n","    train_dataset = DatasetMNIST(\"dirty_mnist/\", train_answer, augmentations=train_transform)\n","    valid_dataset = DatasetMNIST(\"dirty_mnist/\", test_answer, augmentations=valid_transform)\n","\n","\n","    #DataLoader 정의\n","    train_data_loader = DataLoader(\n","        train_dataset,\n","        batch_size = 32,\n","        shuffle = True,\n","        num_workers=4\n","    )\n","    valid_data_loader = DataLoader(\n","        valid_dataset,\n","        batch_size = 32,\n","        shuffle = False,\n","        num_workers=4\n","    )\n","\n","    # 모델 선언\n","    model = Resnet50()\n","    #model = Efficientnet()\n","    model.to(device)# gpu에 모델 할당\n","\n","    # 훈련 옵션 설정\n","    optimizer = torch.optim.Adam(model.parameters(),\n","                                lr = 1e-3)\n","    \n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n","                                                step_size = 5,\n","                                                gamma = 0.9)\n","    \n","    criterion = torch.nn.MultiLabelSoftMarginLoss()\n","    \n","    #체크포인트 불러오기\n","    if os.path.getsize(PATH_CP)==0:\n","      pass\n","    else:\n","      if epoch_cp != -1:\n","          \n","          PATH_CP = \"/content/drive/MyDrive/광운대 해커톤/checkpoint/checkp.pt\"\n","\n","          checkpoint = torch.load(PATH_CP)\n","          model.load_state_dict(checkpoint['model_state_dict'])\n","          optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","          epoch_cp = checkpoint['epoch']\n","          valid_loss = checkpoint['loss']\n","          fold_cp = checkpoint['fold']\n","          model.eval()\n","\n","      #체크포인트 fold로 넘기기\n","      if fold_cp > fold:\n","          continue\n","    \n","    # 훈련 시작\n","    valid_acc_max = 0\n","    early_stop_count = 0\n","    for epoch in range(num_epoch):\n","        #check point 이후부터 학습\n","        if os.path.getsize(PATH_CP)==0:\n","          pass \n","        elif epoch_cp+1 == num_epoch:\n","          break\n","        elif epoch_cp+1 > epoch:\n","          continue\n","        # 1개 epoch 훈련\n","        train_acc_list = []\n","        with tqdm(train_data_loader,#train_data_loader를 iterative하게 반환\n","                total=train_data_loader.__len__(), # train_data_loader의 크기\n","                unit=\"batch\") as train_bar:# 한번 반환하는 smaple의 단위는 \"batch\"\n","            for sample in train_bar:\n","                train_bar.set_description(f\"Train Epoch {epoch}\")\n","                # 갱신할 변수들에 대한 모든 변화도를 0으로 초기화\n","                # 참고)https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html\n","                optimizer.zero_grad()\n","                images, labels = sample['image'], sample['label']\n","                # tensor를 gpu에 올리기 \n","                labels = labels.to(device)\n","                images = images.to(device)\n","\n","\n","\n","\n","                # 모델의 dropoupt, batchnormalization를 train 모드로 설정\n","                model.train()\n","                # .forward()에서 중간 노드의 gradient를 계산\n","                with torch.set_grad_enabled(True):\n","                    # 모델 예측\n","                    probs  = model(images)\n","                    # loss 계산\n","                    loss = criterion(probs, labels)\n","                    # 중간 노드의 gradient로\n","                    # backpropagation을 적용하여\n","                    # gradient 계산\n","                    loss.backward()\n","                    # weight 갱신\n","                    optimizer.step()\n","\n","                    # train accuracy 계산\n","                    probs  = probs.cpu().detach().numpy()\n","                    labels = labels.cpu().detach().numpy()\n","                    preds = probs > 0.5\n","                    batch_acc = (labels == preds).mean()\n","                    train_acc_list.append(batch_acc)\n","                    train_acc = np.mean(train_acc_list)\n","\n","                # 현재 progress bar에 현재 미니배치의 loss 결과 출력\n","                train_bar.set_postfix(train_loss= loss.item(),\n","                                      train_acc = train_acc)\n","                \n","\n","        # 1개 epoch학습 후 Validation 점수 계산\n","        valid_acc_list = []\n","        valid_loss_list = []\n","\n","        with tqdm(valid_data_loader,\n","                total=valid_data_loader.__len__(),\n","                unit=\"batch\") as valid_bar:\n","            for sample in valid_bar:\n","                valid_bar.set_description(f\"Valid Epoch {epoch}\")\n","                optimizer.zero_grad()\n","                images, labels = sample['image'], sample['label']\n","                labels = labels.to(device)\n","                images = images.to(device)\n","\n","                # 모델의 dropoupt, batchnormalization를 eval모드로 설정\n","                model.eval()\n","                # .forward()에서 중간 노드의 gradient를 계산\n","                with torch.no_grad():\n","                    # validation loss만을 계산\n","                    probs  = model(images)\n","                    valid_loss = criterion(probs, labels)\n","\n","                    # train accuracy 계산\n","                    probs  = probs.cpu().detach().numpy()\n","                    labels = labels.cpu().detach().numpy()\n","                    preds = probs > 0.5\n","                    batch_acc = (labels == preds).mean()\n","                    valid_acc_list.append(batch_acc)\n","\n","                valid_acc = np.mean(valid_acc_list)\n","                valid_loss_list.append(valid_loss.item())\n","                valid_loss = np.mean(valid_loss_list)\n","                valid_bar.set_postfix(valid_loss = valid_loss,\n","                                      valid_acc = valid_acc)\n","                \n","            \n","        # Learning rate 조절\n","        lr_scheduler.step()\n","\n","        # 모델 저장\n","        if valid_acc_max < valid_acc:\n","            early_stop_count = 0\n","            valid_acc_max = valid_acc\n","            best_model = model\n","            #MODEL = \"EfficientNet_b8\"\n","            MODEL = \"Resnet50_v2\"\n","            # 모델을 저장할 구글 드라이브 경로\n","            path = \"/content/drive/MyDrive/광운대 해커톤/models/\"\n","            torch.save(best_model, f'{path}{fold}_{MODEL}_{valid_loss.item():2.4f}_epoch_{epoch}.pth')\n","\n","            \n","            #이전보다 valid_acc가 높을 때 체크포인트 저장\n","            torch.save({\n","                'fold': fold,\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': valid_loss\n","                }, PATH_CP)\n","            \n","        else:\n","          early_stop_count+=1\n","        if early_stop_count > 3:\n","           print('early stop')\n","           break\n","\n","    epoch_cp = -1\n","\n","    # 폴드별로 가장 좋은 모델 저장\n","    torch.save(best_model, f'{path}best_model_epoch_{epoch}.pth')"]},{"cell_type":"markdown","metadata":{"id":"E9lTXWY7_yKb"},"source":["## Test Data & Models Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-iJOh15yJQF"},"outputs":[],"source":["#test Dataset 정의\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\n","test_dataset = DatasetMNIST(\"test_dirty_mnist/\", sample_submission)\n","batch_size = 16\n","test_data_loader = DataLoader(\n","    test_dataset,\n","    batch_size = batch_size,\n","    shuffle = False,\n","    num_workers = 3,\n","    drop_last = False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbzUZ2NY5vtL"},"outputs":[],"source":["best_models=[]\n","path = \"/content/drive/MyDrive/광운대 해커톤/best models\"\n","model1 = torch.load(path + \"/0_EfficientNet_b8_0.1328_epoch_28.pth\")\n","model2 = torch.load(path + \"/1_EfficientNet_b8_0.1579_epoch_21.pth\")\n","model3 = torch.load(path + \"/2_EfficientNet_b8_0.1589_epoch_26.pth\")\n","model4 = torch.load(path + \"/3_EfficientNet_b8_0.1670_epoch_24.pth\")\n","model5 = torch.load(path + \"/1_Resnet50_v2_0.2059_epoch_39.pth\")\n","model6 = torch.load(path + \"/2_Resnet50_v2_0.2125_epoch_39.pth\")\n","\n","best_models.append(model1)\n","best_models.append(model2)\n","best_models.append(model3)\n","best_models.append(model4)\n","best_models.append(model5)\n","best_models.append(model6)"]},{"cell_type":"markdown","source":["## TTA"],"metadata":{"id":"r2GIhk_QJT6C"}},{"cell_type":"code","source":["import ttach as tta\n","\n","transformer = tta.Compose(\n","    [\n","        tta.Rotate90(angles=[0,90,180,270]),\n","    ]\n",")"],"metadata":{"id":"ohhxTWUq8Pn6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ensemble / Predict"],"metadata":{"id":"Pj3BB2uvJqpO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFTkJEJD0rFQ"},"outputs":[],"source":["predictions_list = []\n","# 배치 단위로 추론\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\n","\n","for model in best_models:\n","    # 0으로 채워진 array 생성\n","    prediction_array = np.zeros([prediction_df.shape[0],\n","                                 prediction_df.shape[1] -1])\n","    \n","\n","    for idx, sample in enumerate(test_data_loader):\n","        with torch.no_grad():\n","            # 추론\n","            model.eval()\n","            tta_model = tta.ClassificationTTAWrapper(model,transformer,merge_mode='mean')\n","            images = sample['image']\n","            images = images.to(device)\n","            probs  = tta_model(images)\n","            probs = probs.detach().cpu().numpy()\n","\n","            # 예측 결과를 \n","            # prediction_array에 입력\n","            batch_index = batch_size * idx\n","            prediction_array[batch_index: batch_index + images.shape[0],:]\\\n","                         = probs.astype(np.float32)\n","                         \n","    # 채널을 하나 추가하여 list에 append\n","    predictions_list.append(prediction_array[...,np.newaxis])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GFsKkBnaro65"},"outputs":[],"source":["# axis = 2를 기준으로 평균\n","predictions_array = np.concatenate(predictions_list, axis = 2)\n","predictions_mean = predictions_array.mean(axis = 2)\n","\n","#threshold 0.4로 설정\n","predictions_mean = (predictions_mean > 0.4) * 1\n","predictions_mean"]},{"cell_type":"markdown","metadata":{"id":"rW0xr_P9wAEB"},"source":["## 제출파일 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMa5pHWC2C1m"},"outputs":[],"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\n","sample_submission.iloc[:,1:] = predictions_mean\n","sample_submission.to_csv(\"final_efficientb8_resnet50_v2_5.csv\", index = False)\n","sample_submission"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}